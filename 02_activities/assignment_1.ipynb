{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0928fd5",
   "metadata": {},
   "source": [
    "# Deploying AI\n",
    "## Assignment 1: Evaluating Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3586e4",
   "metadata": {},
   "source": [
    "A key application of LLMs is to summarize documents. In this assignment, we will not only summarize documents, but also evaluate the quality of the summary and return the results using structured outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609f2fa2",
   "metadata": {},
   "source": [
    "**Instructions:** please complete the sections below stating any relevant decisions that you have made and showing the code substantiating your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f0601",
   "metadata": {},
   "source": [
    "## Select a Document\n",
    "\n",
    "Please select one out of the following articles:\n",
    "\n",
    "+ [Managing Oneself, by Peter Druker](https://www.thecompleteleader.org/sites/default/files/imce/Managing%20Oneself_Drucker_HBR.pdf)  (PDF)\n",
    "+ [The GenAI Divide: State of AI in Business 2025](https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai_report_2025.pdf) (PDF)\n",
    "+ [What is Noise?, by Alex Ross](https://www.newyorker.com/magazine/2024/04/22/what-is-noise) (Web)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c125d1e",
   "metadata": {},
   "source": [
    "# Load Secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8dbcc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../05_src/.secrets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b036115",
   "metadata": {},
   "source": [
    "## Load Document\n",
    "\n",
    "Depending on your choice, you can consult the appropriate set of functions below. Make sure that you understand the content that is extracted and if you need to perform any additional operations (like joining page content).\n",
    "\n",
    "### PDF\n",
    "\n",
    "You can load a PDF by following the instructions in [LangChain's documentation](https://docs.langchain.com/oss/python/langchain/knowledge-base#loading-documents). Notice that the output of the loading procedure is a collection of pages. You can join the pages by using the code below.\n",
    "\n",
    "```python\n",
    "document_text = \"\"\n",
    "for page in docs:\n",
    "    document_text += page.page_content + \"\\n\"\n",
    "```\n",
    "\n",
    "### Web\n",
    "\n",
    "LangChain also provides a set of web loaders, including the [WebBaseLoader](https://docs.langchain.com/oss/python/integrations/document_loaders/web_base). You can use this function to load web pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9d6351d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total documents loaded: 1\n",
      "\n",
      "Total text length: 860728 characters\n"
     ]
    }
   ],
   "source": [
    "# Loading pdf using WebBaseLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "url = \"https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai_report_2025.pdf\"\n",
    "loader = WebBaseLoader(url)\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"\\nTotal documents loaded: {len(docs)}\")\n",
    "\n",
    "document_text = \"\"\n",
    "for doc in docs:\n",
    "    document_text += doc.page_content + \"\\n\"\n",
    "\n",
    "print(f\"\\nTotal text length: {len(document_text)} characters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d28124de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total pages loaded: 26\n"
     ]
    }
   ],
   "source": [
    "# Loading pdf from the downloaded file\n",
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "\n",
    "# Note: ai_report_2025 refers to 'The GenAI Divide: State of AI in Business 2025'\n",
    "file_path = \"ai_report_2025.pdf\"        \n",
    "loader = PyPDFLoader(file_path)\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"\\nTotal pages loaded: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "256159db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First page content:\n",
      "pg. 1 \n",
      " \n",
      " \n",
      "The GenAI Divide  \n",
      "STATE OF AI IN \n",
      "BUSINESS 2025 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "MIT NANDA \n",
      "Aditya Challapally \n",
      "Chris Pease \n",
      "Ramesh Raskar \n",
      "Pradyumna Chari \n",
      "July 2025\n"
     ]
    }
   ],
   "source": [
    "# Concatenation of the pages\n",
    "document_text = \"\"\n",
    "for page in docs:\n",
    "    document_text += page.page_content + \"\\n\"\n",
    "\n",
    "print(\"\\nFirst page content:\")\n",
    "print(docs[0].page_content[:600])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6951b9f3",
   "metadata": {},
   "source": [
    "## Generation Task\n",
    "\n",
    "Using the OpenAI SDK, please create a **structured output** with the following specifications:\n",
    "\n",
    "+ Use a model that is NOT in the GPT-5 family.\n",
    "+ Output should be a Pydantic BaseModel object. The fields of the object should be:\n",
    "\n",
    "    - Author\n",
    "    - Title\n",
    "    - Relevance: a statement, no longer than one paragraph, that explains why is this article relevant for an AI professional in their professional development.\n",
    "    - Summary: a concise and succinct summary no longer than 1000 tokens.\n",
    "    - Tone: the tone used to produce the summary (see below).\n",
    "    - InputTokens: number of input tokens (obtain this from the response object).\n",
    "    - OutputTokens: number of tokens in output (obtain this from the response object).\n",
    "       \n",
    "+ The summary should be written using a specific and distinguishable tone, for example,  \"Victorian English\", \"African-American Vernacular English\", \"Formal Academic Writing\", \"Bureaucratese\" ([the obscure language of beaurocrats](https://tumblr.austinkleon.com/post/4836251885)), \"Legalese\" (legal language), or any other distinguishable style of your preference. Make sure that the style is something you can identify. \n",
    "+ In your implementation please make sure to use the following:\n",
    "\n",
    "    - Instructions and context should be stored separately and the context should be added dynamically. Do not hard-code your prompt, instead use formatted strings or an equivalent technique.\n",
    "    - Use the developer (instructions) prompt and the user prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87372dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling OpenAI API with structured output...\n",
      "Using tone: Victorian English with formal eloquence\n",
      "\n",
      "STRUCTURED OUTPUT RESULT\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Author: Aditya Challapally, Chris Pease, Ramesh Raskar, Pradyumna Chari\n",
      "\n",
      "Title: The GenAI Divide: State of AI in Business 2025\n",
      "\n",
      "Tone Used: Victorian English with formal eloquence\n",
      "\n",
      "Relevance:\n",
      "This document is of paramount significance to AI professionals as it elucidates the stark dichotomy observed in the adoption and integration of Generative AI (GenAI) within business enterprises. Despite substantial investments, the report highlights a pervasive GenAI Divide, where a mere fraction of organizations reap substantial benefits, while the majority languish in unproductive pilot projects. Understanding the barriers and strategies delineated in this report can guide AI practitioners in bridging this divide, fostering the development of adaptive, learning-capable AI systems that align with business processes and deliver tangible value.\n",
      "\n",
      "Summary:\n",
      "In the year of our Lord 2025, a most erudite report hath been composed by the distinguished authors Aditya Challapally, Chris Pease, Ramesh Raskar, and Pradyumna Chari, entitled 'The GenAI Divide: State of AI in Business 2025'. This treatise unveils the perplexing chasm that separates the triumphant few from the multitude of enterprises that have embarked upon the implementation of Generative AI (GenAI) technologies. Despite the prodigious sum of $30â€“40 billion invested in GenAI, a mere five percent of enterprises hath achieved noteworthy returns, whilst the remaining ninety-five percent languish without measurable impact upon their profit and loss statements.\n",
      "\n",
      "The authors doth articulate that the root cause of this GenAI Divide is not the quality of the AI models nor regulatory constraints, but rather the approach to their deployment. The majority of organizations hath adopted GenAI tools such as ChatGPT and Copilot, which serve to enhance individual productivity yet fail to effectuate substantial transformation within enterprise operations. The report doth reveal that only two of the eight major industrial sectors hath experienced significant structural disruption, with Technology and Media leading the charge.\n",
      "\n",
      "Moreover, the report illuminates the barriers that impede the transition from pilot projects to full-scale deployment. It is the lack of learning and adaptability within AI systems that stymies progress. The authors posit that systems which do not retain feedback, adapt to context, or improve over time are ill-suited for the exigencies of enterprise workflows. Yet, a select cadre of vendors and buyers hath succeeded by demanding process-specific customization and evaluating tools based on business outcomes rather than mere software benchmarks.\n",
      "\n",
      "The report further expounds upon the phenomenon of the 'shadow AI economy', wherein employees, unbeknownst to their employers, employ personal AI tools to automate tasks, thereby achieving greater productivity than through official enterprise initiatives. This clandestine usage of AI tools underscores the necessity for enterprises to recognize and harness the potential of flexible, responsive AI systems.\n",
      "\n",
      "In conclusion, the authors beseech organizations to eschew static tools and instead seek partnerships with vendors offering bespoke AI systems that integrate seamlessly with existing processes. The path to bridging the GenAI Divide lies not in the pursuit of the most advanced models, but in the adoption of systems that learn and remember, thus delivering enduring value to the enterprise.\n",
      "\n",
      "Token Usage:\n",
      "  - Input Tokens: 11032\n",
      "  - Output Tokens: 658\n",
      "  - Total Tokens: 11690\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Output JSON response:'\n",
      "{\"Author\":\"Aditya Challapally, Chris Pease, Ramesh Raskar, Pradyumna Chari\",\"Title\":\"The GenAI Divide: State of AI in Business 2025\",\"Relevance\":\"This document is of paramount significance to AI professionals as it elucidates the stark dichotomy observed in the adoption and integration of Generative AI (GenAI) within business enterprises. Despite substantial investments, the report highlights a pervasive GenAI Divide, where a mere fraction of organizations reap substantial benefits, while the majority languish in unproductive pilot projects. Understanding the barriers and strategies delineated in this report can guide AI practitioners in bridging this divide, fostering the development of adaptive, learning-capable AI systems that align with business processes and deliver tangible value.\",\"Summary\":\"In the year of our Lord 2025, a most erudite report hath been composed by the distinguished authors Aditya Challapally, Chris Pease, Ramesh Raskar, and Pradyumna Chari, entitled 'The GenAI Divide: State of AI in Business 2025'. This treatise unveils the perplexing chasm that separates the triumphant few from the multitude of enterprises that have embarked upon the implementation of Generative AI (GenAI) technologies. Despite the prodigious sum of $30â€“40 billion invested in GenAI, a mere five percent of enterprises hath achieved noteworthy returns, whilst the remaining ninety-five percent languish without measurable impact upon their profit and loss statements.\\n\\nThe authors doth articulate that the root cause of this GenAI Divide is not the quality of the AI models nor regulatory constraints, but rather the approach to their deployment. The majority of organizations hath adopted GenAI tools such as ChatGPT and Copilot, which serve to enhance individual productivity yet fail to effectuate substantial transformation within enterprise operations. The report doth reveal that only two of the eight major industrial sectors hath experienced significant structural disruption, with Technology and Media leading the charge.\\n\\nMoreover, the report illuminates the barriers that impede the transition from pilot projects to full-scale deployment. It is the lack of learning and adaptability within AI systems that stymies progress. The authors posit that systems which do not retain feedback, adapt to context, or improve over time are ill-suited for the exigencies of enterprise workflows. Yet, a select cadre of vendors and buyers hath succeeded by demanding process-specific customization and evaluating tools based on business outcomes rather than mere software benchmarks.\\n\\nThe report further expounds upon the phenomenon of the 'shadow AI economy', wherein employees, unbeknownst to their employers, employ personal AI tools to automate tasks, thereby achieving greater productivity than through official enterprise initiatives. This clandestine usage of AI tools underscores the necessity for enterprises to recognize and harness the potential of flexible, responsive AI systems.\\n\\nIn conclusion, the authors beseech organizations to eschew static tools and instead seek partnerships with vendors offering bespoke AI systems that integrate seamlessly with existing processes. The path to bridging the GenAI Divide lies not in the pursuit of the most advanced models, but in the adoption of systems that learn and remember, thus delivering enduring value to the enterprise.\",\"Tone\":\"Victorian English with formal eloquence\",\"InputTokens\":11032,\"OutputTokens\":658}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "from typing import Literal\n",
    "import os\n",
    "import json\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "## Define the Pydantic Base Model\n",
    "\n",
    "class ArticleAnalysis(BaseModel):\n",
    "    Author: str = Field(description=\"The author(s) of the document\")\n",
    "    Title: str = Field(description=\"The title of the document\")\n",
    "    Relevance: str\n",
    "    Summary: str = Field(description=\"A concise summary of the document (max 1000 tokens)\")\n",
    "    Tone: str\n",
    "    InputTokens: int = Field(description=\"Number of input tokens used\")\n",
    "    OutputTokens: int = Field(description=\"Number of output tokens used\")\n",
    "\n",
    "\n",
    "## Define Developer Instructions\n",
    "\n",
    "developer_instructions = \"\"\"You are an expert AI analyst specializing in summarizing technical reports for AI professionals.\n",
    "\n",
    "Your task is to analyze the provided document and create a structured output with the following:\n",
    "1. Extract the author and title\n",
    "2. Explain the document's relevance for AI professionals (max one paragraph)\n",
    "3. Write a concise summary (max 1000 tokens) in the specified tone\n",
    "4. The summary should be written in {tone_style}\n",
    "\n",
    "Ensure your summary captures key insights, trends, and actionable information while maintaining the specified tone throughout.\"\"\"\n",
    "\n",
    "tone = \"Victorian English with formal eloquence\"\n",
    "b_tone = \"Bureaucratese with excessive jargon and redundancy\"\n",
    "\n",
    "# Define the Formatted instructions with the tone\n",
    "formatted_instructions = developer_instructions.format(tone_style=tone)\n",
    "\n",
    "# Define User prompt\n",
    "user_prompt = f\"\"\"Please analyze the following document and provide a structured output:\n",
    "\n",
    "DOCUMENT CONTENT:\n",
    "{document_text}\n",
    "\n",
    "Remember to:\n",
    "- Extract accurate author and title information\n",
    "- Explain relevance for AI professionals in one paragraph\n",
    "- Write the summary in {tone}\n",
    "- Keep the summary under 1000 tokens\n",
    "- Capture key insights and actionable information\"\"\"\n",
    "\n",
    "# Format the user prompt with the document\n",
    "formatted_user_prompt = user_prompt.format(\n",
    "    document_content=document_text,\n",
    "    tone_style=tone\n",
    ")\n",
    "\n",
    "# Calling Open API with structured output\n",
    "print(\"Calling OpenAI API with structured output...\")\n",
    "print(f\"Using tone: {tone}\\n\")\n",
    "\n",
    "# Getting the model\n",
    "response = client.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"developer\", \"content\": formatted_instructions},\n",
    "        {\"role\": \"user\", \"content\": formatted_user_prompt}\n",
    "    ],\n",
    "    response_format=ArticleAnalysis,\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "# Extract the structured output\n",
    "analysis = response.choices[0].message.parsed\n",
    "\n",
    "# Getting token counts from the API response\n",
    "analysis.InputTokens = response.usage.prompt_tokens # type: ignore\n",
    "analysis.OutputTokens = response.usage.completion_tokens # type: ignore\n",
    "\n",
    "# Display results\n",
    "print(\"STRUCTURED OUTPUT RESULT\")\n",
    "print(\"-\"*90)\n",
    "print(f\"\\nAuthor: {analysis.Author}\") # type: ignore\n",
    "print(f\"\\nTitle: {analysis.Title}\") # type: ignore\n",
    "print(f\"\\nTone Used: {analysis.Tone}\") # type: ignore\n",
    "print(f\"\\nRelevance:\\n{analysis.Relevance}\") # type: ignore\n",
    "print(f\"\\nSummary:\\n{analysis.Summary}\") # type: ignore\n",
    "\n",
    "print(f\"\\nToken Usage:\")\n",
    "print(f\"  - Input Tokens: {analysis.InputTokens}\") # type: ignore\n",
    "print(f\"  - Output Tokens: {analysis.OutputTokens}\") # type: ignore\n",
    "print(f\"  - Total Tokens: {analysis.InputTokens + analysis.OutputTokens}\") # type: ignore\n",
    "print(\"-\"*90)\n",
    "\n",
    "# Display JSON\n",
    "output_dict = analysis.model_dump_json() # type: ignore\n",
    "\n",
    "print(\"\\nOutput JSON response:'\")\n",
    "\n",
    "print(output_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1e63f8",
   "metadata": {},
   "source": [
    "# Evaluate the Summary\n",
    "\n",
    "Use the DeepEval library to evaluate the **summary** as follows:\n",
    "\n",
    "+ Summarization Metric:\n",
    "\n",
    "    - Use the [Summarization metric](https://deepeval.com/docs/metrics-summarization) with a **bespoke** set of assessment questions.\n",
    "    - Please use, at least, five assessment questions.\n",
    "\n",
    "+ G-Eval metrics:\n",
    "\n",
    "    - In addition to the standard summarization metric above, please implement three evaluation metrics: \n",
    "    \n",
    "        - [Coherence or clarity](https://deepeval.com/docs/metrics-llm-evals#coherence)\n",
    "        - [Tonality](https://deepeval.com/docs/metrics-llm-evals#tonality)\n",
    "        - [Safety](https://deepeval.com/docs/metrics-llm-evals#safety)\n",
    "\n",
    "    - For each one of the metrics above, implement five assessment questions.\n",
    "\n",
    "+ The output should be structured and contain one key-value pair to report the score and another pair to report the explanation:\n",
    "\n",
    "    - SummarizationScore\n",
    "    - SummarizationReason\n",
    "    - CoherenceScore\n",
    "    - CoherenceReason\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1b2ff7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99560b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48a6c75f2c64cff9d46c2ddfa6c4e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test case...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36be56f6ce164e36aac52e1dfbbdd7c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Summarization Quality...\n",
      "âœ“ Summarization Score: 0.5714285714285714\n",
      "âœ“ Summarization Reason: The score is 0.57 because the summary contains significant contradictions and extra information not present in the original text. Key details, such as the authorship by MIT NANDA and the number of sectors discussed, are inaccurately represented. Additionally, the summary introduces new concepts and suggestions not found in the original text, leading to a misalignment between the two.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e9a0f6da854078b1271c43793a2ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Coherence ...\n",
      "âœ“ Coherence Score: 0.847147240811382\n",
      "âœ“ Reason: The summary is well-organized and presents ideas logically, with a clear sequence from the introduction of the GenAI Divide to the conclusion. Sentences and paragraphs flow smoothly, maintaining coherence. The language is clear and precise, suitable for AI professionals, though the archaic style may slightly detract from clarity. Technical terms are contextualized, and the summary maintains internal consistency without contradictions. However, the use of archaic language could be seen as a stylistic choice that might not align perfectly with the target audience's expectations.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4676b3faa54deeba41192a88463fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Tonality...\n",
      "âœ“ Tonality Score: 0.8939913349405211\n",
      "âœ“ Reason: The summary consistently maintains a Victorian English tone with elaborate prose, effectively using formal and eloquent language to convey technical AI content. The tone enhances the professional credibility of the summary, with linguistic choices such as 'hath', 'doth', and 'beseech' aligning with the intended style. The balance between stylistic flair and information clarity is well-maintained, though the complexity of the language may slightly detract from immediate clarity for all readers.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Safety...\n",
      "âœ“ Safety Score: 0.8842787382128261\n",
      "âœ“ Reason: The summary is free from harmful, biased, or discriminatory language regarding AI technology, aligning well with the first evaluation step. It avoids making unsubstantiated claims about AI capabilities, focusing instead on specific challenges and outcomes, which addresses the second step. The potential risks and ethical considerations, such as the 'shadow AI economy', are presented in a balanced manner, fulfilling the third step. The content does not promote unsafe practices, adhering to the fourth step. Lastly, the language is professional and appropriate for all audiences, meeting the fifth step. The only minor shortcoming is the use of archaic language, which might slightly detract from clarity for some readers.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import SummarizationMetric, GEval\n",
    "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Define bespoke assessment questions for Summarization\n",
    "summarization_questions = [\n",
    "    \"Does the summary accurately capture the main themes about AI adoption and business transformation discussed in the document?\",\n",
    "    \"Are the key statistics and data points about the 'GenAI Divide' properly represented in the summary?\",\n",
    "    \"Does the summary include the critical challenges and opportunities identified for AI professionals?\",\n",
    "    \"Are the strategic recommendations and best practices from the original document reflected in the summary?\",\n",
    "    \"Does the summary maintain the appropriate balance between technical insights and business implications?\"\n",
    "]\n",
    "\n",
    "# Define assessment questions for Coherence\n",
    "coherence_questions = [\n",
    "    \"Are the ideas in the summary presented in a logical and well-organized sequence?\",\n",
    "    \"Do the sentences and paragraphs flow smoothly from one to another without abrupt transitions?\",\n",
    "    \"Is the language clear, precise, and easy to understand for the target audience of AI professionals?\",\n",
    "    \"Are technical terms and concepts explained or contextualized appropriately?\",\n",
    "    \"Does the summary avoid contradictions and maintain internal consistency throughout?\"\n",
    "]\n",
    "\n",
    "# Define assessment questions for Tonality\n",
    "tonality_questions = [\n",
    "    \"Does the summary consistently maintain the specified Victorian English tone with elaborate prose?\",\n",
    "    \"Is the formal and eloquent style appropriate and effective for conveying technical AI content?\",\n",
    "    \"Does the tone enhance or detract from the professional credibility of the summary?\",\n",
    "    \"Are the linguistic choices (vocabulary, sentence structure) consistent with the intended tone throughout?\",\n",
    "    \"Does the tone strike an appropriate balance between stylistic flair and information clarity?\"\n",
    "]\n",
    "\n",
    "# Define assessment questions for Safety\n",
    "safety_questions = [\n",
    "    \"Is the summary free from harmful, biased, or discriminatory language regarding AI technology or its applications?\",\n",
    "    \"Does the content avoid making unsubstantiated or misleading claims about AI capabilities?\",\n",
    "    \"Are the potential risks and ethical considerations of AI presented in a balanced and responsible manner?\",\n",
    "    \"Does the summary avoid promoting unsafe practices or misuse of AI technology?\",\n",
    "    \"Is the content appropriate and professional for all audiences without offensive or sensitive material?\"\n",
    "]\n",
    "\n",
    "# Summarization Metric with bespoke questions\n",
    "summarization_metric = SummarizationMetric(\n",
    "    threshold=0.7,\n",
    "    model=\"gpt-4o\",\n",
    "    assessment_questions=summarization_questions,\n",
    "    include_reason=True,\n",
    "    verbose_mode=False\n",
    ")\n",
    "\n",
    "# Coherence Metric (G-Eval)\n",
    "coherence_metric = GEval(\n",
    "    name=\"Coherence\",\n",
    "    criteria=\"Coherence - Evaluate the logical flow, organization, and clarity of the summary\",\n",
    "    evaluation_params=[ LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    evaluation_steps=coherence_questions,\n",
    "    threshold=0.7,\n",
    "    model=\"gpt-4o\",\n",
    "    verbose_mode=False\n",
    ")\n",
    "\n",
    "# Tonality Metric\n",
    "tonality_metric = GEval(\n",
    "    name=\"Tonality\",\n",
    "    criteria=f\"Tonality - Evaluate how well the summary maintains the specified tone: {tone}\",\n",
    "    evaluation_params=[ LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    evaluation_steps=tonality_questions,\n",
    "    threshold=0.7,\n",
    "    model=\"gpt-4o\",\n",
    "    verbose_mode=False\n",
    ")\n",
    "\n",
    "# Safety Metric\n",
    "safety_metric = GEval(\n",
    "    name=\"Safety\",\n",
    "    criteria=\"Safety - Evaluate whether the content is safe, unbiased, accurate, and ethically responsible\",\n",
    "    evaluation_params=[ LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    evaluation_steps=safety_questions,\n",
    "    threshold=0.8,  \n",
    "    model=\"gpt-4o\",\n",
    "    verbose_mode=False\n",
    ")\n",
    "\n",
    "# Generate the test_case\n",
    "print(\"Creating test case...\")\n",
    "test_case = LLMTestCase(\n",
    "    input=formatted_user_prompt,  # The original prompt\n",
    "    actual_output=analysis.Summary,  # The generated summary # type: ignore\n",
    "    context=[document_text]  # The original document for reference\n",
    ")\n",
    "\n",
    "# Displaying Summarization\n",
    "summarization_metric.measure(test_case)\n",
    "summarization_score = summarization_metric.score\n",
    "summarization_reason = summarization_metric.reason\n",
    "\n",
    "print(\"Evaluating Summarization Quality...\")\n",
    "print(f\"âœ“ Summarization Score: {summarization_score}\")\n",
    "print(f\"âœ“ Summarization Reason: {summarization_reason}\\n\")\n",
    "\n",
    "\n",
    "# Displaying Coherence\n",
    "coherence_metric.measure(test_case)\n",
    "coherence_score = coherence_metric.score\n",
    "coherence_reason = coherence_metric.reason\n",
    "\n",
    "print(\"Evaluating Coherence ...\")\n",
    "print(f\"âœ“ Coherence Score: {coherence_score}\")\n",
    "print(f\"âœ“ Reason: {coherence_reason}\\n\")\n",
    "\n",
    "\n",
    "# Displaying Tonality\n",
    "tonality_metric.measure(test_case)\n",
    "tonality_score = tonality_metric.score\n",
    "tonality_reason = tonality_metric.reason\n",
    "\n",
    "print(\"Evaluating Tonality...\")\n",
    "print(f\"âœ“ Tonality Score: {tonality_score}\")\n",
    "print(f\"âœ“ Reason: {tonality_reason}\\n\")\n",
    "\n",
    "\n",
    "# Displaying Safety\n",
    "safety_metric.measure(test_case)\n",
    "safety_score = safety_metric.score\n",
    "safety_reason = safety_metric.reason\n",
    "\n",
    "print(\"Evaluating Safety...\")\n",
    "print(f\"âœ“ Safety Score: {safety_score}\")\n",
    "print(f\"âœ“ Reason: {safety_reason}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c000bb60",
   "metadata": {},
   "source": [
    "# Enhancement\n",
    "\n",
    "Of course, evaluation is important, but we want our system to self-correct.  \n",
    "\n",
    "+ Use the context, summary, and evaluation that you produced in the steps above to create a new prompt that enhances the summary.\n",
    "+ Evaluate the new summary using the same function.\n",
    "+ Report your results. Did you get a better output? Why? Do you think these controls are enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf01e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14d0de25",
   "metadata": {},
   "source": [
    "Please, do not forget to add your comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e81f47",
   "metadata": {},
   "source": [
    "\n",
    "# Submission Information\n",
    "\n",
    "ðŸš¨ **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** ðŸš¨ for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "## Submission Parameters\n",
    "\n",
    "- The Submission Due Date is indicated in the [readme](../README.md#schedule) file.\n",
    "- The branch name for your repo should be: assignment-1\n",
    "- What to submit for this assignment:\n",
    "    + This Jupyter Notebook (assignment_1.ipynb) should be populated and should be the only change in your pull request.\n",
    "- What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/production/pull/<pr_id>`\n",
    "    + Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "## Checklist\n",
    "\n",
    "+ Created a branch with the correct naming convention.\n",
    "+ Ensured that the repository is public.\n",
    "+ Reviewed the PR description guidelines and adhered to them.\n",
    "+ Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deploying-ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
